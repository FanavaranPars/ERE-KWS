{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b484522-e710-46c9-8dab-2b27c7294619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import hazm\n",
    "import unicodedata\n",
    "import Levenshtein\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c919f2-e5c3-4c25-8671-8fa16f724989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72142128-cd4e-4115-8fc2-d95e48d3cff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c539cc0fa7c54b5fbcbfe4b4b141d2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = \"../Data/KeyWords\"\n",
    "\n",
    "FILENAME_DICT = {}\n",
    "for lang in tqdm(os.listdir(data_path)):\n",
    "    all_filenames = glob(os.path.join(data_path, \"{}/clips/*/*.opus\".format(lang)))\n",
    "\n",
    "    filename_dict = {}\n",
    "    for filename in all_filenames:\n",
    "        folder = filename.split(os.path.sep)[-2]\n",
    "    \n",
    "        if folder in filename_dict:\n",
    "            filename_dict[folder].append(filename)\n",
    "        else:\n",
    "            filename_dict[folder] = [filename]\n",
    "\n",
    "    FILENAME_DICT[lang] = filename_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b0f0d1-b12e-4ca5-a798-1d18cc81824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7514350\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(FILENAME_DICT[lang][folder]) for lang in FILENAME_DICT for folder in FILENAME_DICT[lang]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58035de-97b1-4668-ad26-e2765674b6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49bf4f1-af51-46b0-8e61-834d7f9a36df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d531d-2c0a-4ca9-902b-df26dbed4486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ff64fc-9d81-4812-8a57-49da32f201d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = hazm.Normalizer(persian_style=False)\n",
    "\n",
    "translation_src = \"إ٫ٲٳٴڃڄﭪﭬﯔﯕﯖﯗﯘﯙﯞﯧﯨﯩﯼﯽﯾﯿﴽﺓةﺔۀأؤیؠػػؽؾؿكيٮٯٷٸٹٺٻټٽٿڀځٵٶٷٸٹٺٻټٽٿڀځڂڅڇڈډڊڋڌڍڎڏڐڑڒړڔڕږڗڙښڛڜڝڞڟڠڡڢڣڤڥڦڧڨڪګڬڭڮڰڱڲڳڴڵڶڷڸڹںڻڼڽھڿہۂۃۄۅۆۇۈۉۊۋۏۍێېۑےۓەۮۯۺۻۼۿݐݑݒݓݔݕݖݗݘݙݚݛݜݝݞݟݠݡݢݣݤݥݦݧݨݩݪݫݬݭݮݯݰݱݲݳݴݵݶݷݸݹݺݻݼݽݾݿࢠࢡࢢࢣࢤࢥࢦࢧࢨࢩࢪࢫࢮࢯࢰࢱࢬࢲࢳࢴࢶࢷࢸࢹࢺࢻࢼࢽﭐﭑﭒﭓﭔﭕﭖﭗﭘﭙﭚﭛﭜﭝﭞﭟﭠﭡﭢﭣﭤﭥﭦﭧﭨﭩﭮﭯﭰﭱﭲﭳﭴﭵﭶﭷﭸﭹﭺﭻﭼﭽﭾﭿﮀﮁﮂﮃﮄﮅﮆﮇﮈﮉﮊﮋﮌﮍﮎﮏﮐﮑﮒﮓﮔﮕﮖﮗﮘﮙﮚﮛﮜﮝﮞﮟﮠﮡﮢﮣﮤﮥﮦﮧﮨﮩﮪﮫﮬﮭﮮﮯﮰﮱﺀﺁﺃﺄﺅﺆﺇﺈﺉﺊﺋﺌﺍﺎﺏﺐﺑﺒﺕﺖﺗﺘﺙﺚﺛﺜﺝﺞﺟﺠﺡﺢﺣﺤﺥﺦﺧﺨﺩﺪﺫﺬﺭﺮﺯﺰﺱﺲﺳﺴﺵﺶﺷﺸﺹﺺﺻﺼﺽﺾﺿﻀﻁﻂﻃﻄﻅﻆﻇﻈﻉﻊﻋﻌﻍﻎﻏﻐﻑﻒﻓﻔﻕﻖﻗﻘﻙﻚﻛﻜﻝﻞﻟﻠﻡﻢﻣﻤﻥﻦﻧﻨﻩﻪﻫﻬﻭﻮﻯﻰﻱﻲﻳﻴىكي“” \"\n",
    "translation_dst = (\n",
    "            'ا.ااءججفقکککوووویییییییاههههاوییککیییکیبقویتتبتتتبحاوویتتبتتتبحححچدددددددددررررررررسسسصصطعففففففققکککککگگگگگللللنننننهچهههوووووووووییییییهدرشضغهبببببببححددرسعععففکککممنننلررسححسرحاایییووییحسسکببجطفقلمییرودصگویزعکبپتریفقنااببببپپپپببببتتتتتتتتتتتتففففححححححححچچچچچچچچددددددددژژررککککگگگگگگگگگگگگننننننههههههههههییییءاااووااییییااببببتتتتثثثثججججححححخخخخددذذررززسسسسششششصصصصضضضضططططظظظظععععغغغغففففققققککککللللممممننننههههوویییییییکی\"\" '\n",
    "        )\n",
    "\n",
    "number_translation_src = \"۰۱۲۳۴۵۶۷۸۹٪٠١٢٣٤٥٦٧٨٩\"\n",
    "number_translation_dst = \"0123456789%0123456789\"\n",
    "\n",
    "\n",
    "normalizer.translation_src = translation_src\n",
    "normalizer.translation_dst = translation_dst\n",
    "\n",
    "normalizer.number_translation_src = number_translation_src\n",
    "normalizer.number_translation_dst = number_translation_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05199211-c90c-4017-ad3f-d1fcf1f5bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"special_characters.txt\", \"r\") as f:\n",
    "    SPECIAL_CHARS = f.read().strip().split(\"\\n\")\n",
    "    \n",
    "def remove_special_characters(text, replace= \"\"):\n",
    "    return re.sub('[' + re.escape(\"\".join(SPECIAL_CHARS)) + ']', replace, text)\n",
    "\n",
    "def strip_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2632cc73-3725-43db-a253-664503d7267e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5907b8e-fc5f-4030-9614-bbc5a0773c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7ee4cee-d8bc-46f7-ad81-3d5ed7a924c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_filename_dict(filename_dict, folders, n_thershold=50):\n",
    "    folder_mapping = {}\n",
    "    for folder in folders:\n",
    "        folder_ = normalizer.normalize(folder)\n",
    "        folder_ = strip_accents(folder_)\n",
    "        new_folder = remove_special_characters(folder_)\n",
    "    \n",
    "        if new_folder == folder_:\n",
    "            folder_mapping[folder] = new_folder\n",
    "                \n",
    "            \n",
    "    buffer = {}\n",
    "    for folder in folder_mapping:\n",
    "        new_folder = folder_mapping[folder]\n",
    "        \n",
    "        if new_folder in buffer:\n",
    "            buffer[new_folder] += filename_dict[folder]\n",
    "        else:\n",
    "            buffer[new_folder] = filename_dict[folder]\n",
    "    filename_dict = buffer\n",
    "\n",
    "    buffer = {}\n",
    "    for folder in filename_dict:\n",
    "        if len(filename_dict[folder]) >= n_thershold:\n",
    "            buffer[folder] = filename_dict[folder]\n",
    "    filename_dict = buffer\n",
    "\n",
    "    return filename_dict\n",
    "\n",
    "\n",
    "def filter_vocabs(filename_dict, folders):\n",
    "    \n",
    "    folders = sorted(list(filename_dict.keys()))\n",
    "    folder_mapping = {}\n",
    "    for folder in tqdm(folders):\n",
    "        \n",
    "        new_folders = folders.copy()\n",
    "        new_folders.remove(folder)\n",
    "    \n",
    "        MIN = np.inf\n",
    "        for folder_ in new_folders:\n",
    "            dist = Levenshtein.distance(folder, folder_, weights=(1,1,1))\n",
    "            if dist <= MIN:\n",
    "                MIN = dist\n",
    "    \n",
    "                if MIN == 1:\n",
    "                    if folder in folder_mapping:\n",
    "                        folder_mapping[folder].append(folder_)\n",
    "                    else:\n",
    "                        folder_mapping[folder] = [folder_]\n",
    "        \n",
    "    \n",
    "    \n",
    "    deleted_folders, selected_folders = [], []\n",
    "    for count, folder in enumerate(sorted(folder_mapping.keys())):\n",
    "        SET = [folder] + folder_mapping[folder]\n",
    "        SET = [f for f in SET if len(f) >= 3]\n",
    "        SET = list(set(SET) - set(deleted_folders + selected_folders))\n",
    "        \n",
    "        \n",
    "        SET_ = SET.copy()\n",
    "        for f in SET:\n",
    "            for f_ in selected_folders:\n",
    "                dist = Levenshtein.distance(f, f_, weights=(1,1,1))\n",
    "                if dist == 1:\n",
    "                    SET_.remove(f)\n",
    "                    break\n",
    "        SET = SET_\n",
    "        \n",
    "    \n",
    "        if len(SET):\n",
    "            MAX = 0\n",
    "            for f in SET:\n",
    "                LEN = len(filename_dict[f])\n",
    "                if LEN > MAX:\n",
    "                    selected = f\n",
    "                    MAX = len(filename_dict[f])\n",
    "        \n",
    "            SET.remove(selected)\n",
    "            \n",
    "            deleted_folders += SET\n",
    "            selected_folders.append(selected)\n",
    "\n",
    "    return selected_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1327674-5a52-44a4-b94a-d442fd0a6146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca833ce7dbe41a08bdbe7e75a14b442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** fa *****\n",
      "3343 956883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c043304626704a988368aa1578c71212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851 329303\n"
     ]
    }
   ],
   "source": [
    "BUFFER = {}\n",
    "\n",
    "for lang in tqdm(os.listdir(data_path)):\n",
    "    print(5 * \"*\", lang, 5 * \"*\")\n",
    "    \n",
    "    filename_dict = FILENAME_DICT[lang].copy()\n",
    "    folders = sorted(list(filename_dict.keys()))\n",
    "    \n",
    "    filename_dict = filter_filename_dict(filename_dict, folders)\n",
    "    folders = sorted(list(filename_dict.keys()))\n",
    "    print(len(folders), sum([len(a) for a in filename_dict.values()]))\n",
    "    \n",
    "    \n",
    "    if len(folders) > 20:\n",
    "        selected_folders = filter_vocabs(filename_dict, folders)\n",
    "        LEN = sum([len(filename_dict[folder]) for folder in selected_folders])\n",
    "        print(len(selected_folders), LEN)\n",
    "\n",
    "        buffer = {}\n",
    "        for folder in selected_folders:\n",
    "            buffer[folder] = filename_dict[folder]\n",
    "\n",
    "        BUFFER[lang] = {\n",
    "            \"filename_dict\" : buffer,\n",
    "            \"dataset_length\": LEN,\n",
    "            \"folders\" : selected_folders,\n",
    "        }\n",
    "    else:\n",
    "        print(\"Lang has not good resources !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfcbbad0-b86a-4837-9f55-965118d7ebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329303\n",
      "851\n"
     ]
    }
   ],
   "source": [
    "print(sum([BUFFER[lang][\"dataset_length\"] for lang in BUFFER]))\n",
    "print(sum([len(BUFFER[lang][\"folders\"]) for lang in BUFFER]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4fc3855-6b29-4163-b16f-71ead1632a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('FILENAME_DICT.json', 'w') as fp:\n",
    "    json.dump(BUFFER, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38db035-3eb3-44e2-8e4e-214e20c918ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c734b-aef7-4be9-baf3-f5cb9fbb5ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea523c-a1e2-4321-9cf9-6f01526c3e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864a2bbb-dc11-46e3-8d5e-c78a6fc57037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad19e839e8294c01beaff4b9f881e18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ar *****\n",
      "18 4292\n",
      "Lang has not good resources !!!\n",
      "***** mn *****\n",
      "22 4450\n",
      "***** pl *****\n",
      "293 100705\n",
      "***** et *****\n",
      "45 10061\n",
      "***** rm-sursilv *****\n",
      "12 2112\n",
      "Lang has not good resources !!!\n",
      "***** ha *****\n",
      "4 282\n",
      "Lang has not good resources !!!\n",
      "***** tr *****\n",
      "28 10054\n",
      "***** fr *****\n",
      "1445 918718\n",
      "***** cs *****\n",
      "64 13506\n",
      "***** rw *****\n",
      "1022 448855\n",
      "***** ro *****\n",
      "11 2032\n",
      "Lang has not good resources !!!\n",
      "***** sl *****\n",
      "3 447\n",
      "Lang has not good resources !!!\n",
      "***** lt *****\n",
      "5 558\n",
      "Lang has not good resources !!!\n",
      "***** lv *****\n",
      "12 2275\n",
      "Lang has not good resources !!!\n",
      "***** mt *****\n",
      "17 3504\n",
      "Lang has not good resources !!!\n",
      "***** fa *****\n",
      "851 329303\n",
      "***** nl *****\n",
      "116 60075\n",
      "***** fy-NL *****\n",
      "22 5798\n",
      "***** cnh *****\n",
      "5 1001\n",
      "Lang has not good resources !!!\n",
      "***** ky *****\n",
      "19 4867\n",
      "Lang has not good resources !!!\n",
      "***** eo *****\n",
      "183 65788\n",
      "***** id *****\n",
      "19 7979\n",
      "Lang has not good resources !!!\n",
      "***** sah *****\n",
      "3 475\n",
      "Lang has not good resources !!!\n",
      "***** de *****\n",
      "1596 1316509\n",
      "***** pt *****\n",
      "134 58181\n",
      "***** ga-IE *****\n",
      "8 624\n",
      "Lang has not good resources !!!\n",
      "***** ia *****\n",
      "8 2097\n",
      "Lang has not good resources !!!\n",
      "***** cy *****\n",
      "273 117864\n",
      "***** ca *****\n",
      "1376 675139\n",
      "***** en *****\n",
      "2543 2556601\n",
      "***** ru *****\n",
      "402 116187\n",
      "***** sv-SE *****\n",
      "22 13821\n",
      "***** tt *****\n",
      "69 18089\n",
      "***** eu *****\n",
      "265 106799\n",
      "***** el *****\n",
      "12 3101\n",
      "Lang has not good resources !!!\n",
      "***** uk *****\n",
      "36 6965\n",
      "***** es *****\n",
      "849 388172\n",
      "***** br *****\n",
      "12 2525\n",
      "Lang has not good resources !!!\n",
      "***** it *****\n",
      "374 135445\n"
     ]
    }
   ],
   "source": [
    "BUFFER = {}\n",
    "\n",
    "for lang in tqdm(os.listdir(data_path)):\n",
    "    print(5 * \"*\", lang, 5 * \"*\")\n",
    "    \n",
    "    filename_dict = FILENAME_DICT[lang].copy()\n",
    "    folders = sorted(list(filename_dict.keys()))\n",
    "    \n",
    "    filename_dict = filter_filename_dict(filename_dict, folders)\n",
    "    folders = sorted(list(filename_dict.keys()))\n",
    "    print(len(folders), sum([len(a) for a in filename_dict.values()]))\n",
    "    \n",
    "    if len(folders) > 20:\n",
    "        LEN = sum([len(filename_dict[folder]) for folder in folders])\n",
    "\n",
    "        BUFFER[lang] = {\n",
    "            \"filename_dict\" : filename_dict,\n",
    "            \"dataset_length\": LEN,\n",
    "            \"folders\" : folders,\n",
    "        }\n",
    "    else:\n",
    "        print(\"Lang has not good resources !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03045f81-0fbd-42f2-8385-e4c8f3ac1910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7477085\n",
      "12030\n"
     ]
    }
   ],
   "source": [
    "print(sum([BUFFER[lang][\"dataset_length\"] for lang in BUFFER]))\n",
    "print(sum([len(BUFFER[lang][\"folders\"]) for lang in BUFFER]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6515587e-9b43-4f52-9836-c74f98af8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('FILENAME_DICT.json', 'w') as fp:\n",
    "    json.dump(BUFFER, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f489640-621d-4da4-b7c9-4aa4ed79786e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca2d7f-1702-4570-b815-4d0e0009170d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce6325-ec81-411d-af34-864e0a3944a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46337f12-3000-47d8-9f3c-3c13526f293c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db776dac-4878-4685-b5a8-0bfdffc72cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import textgrid\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "from mpire import WorkerPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb5ff2-e3e3-4107-a5fe-2355538f6a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9e522-30f8-47bc-becb-a2d8f4216114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('FILENAME_DICT.json', 'r') as fp:\n",
    "    FILENAME_DICT = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c7be6-44ca-49fb-9c6f-9d9c05a6a898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52277e9-6b75-444d-b65c-8860e927da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = \"fa\"\n",
    "textgrid_filenames = glob(\"../Data/alignments/fa/mnt/disks/std750/data/common-voice-forced-alignments/fa/alignments/*/*.TextGrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662aff6-e478-40b4-a505-bb42694873d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEECH_TEMPLATE = \"../Data/cv-corpus/fa/clips/{}.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d414caa-8706-44a0-add6-3df92506f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2keyword = {}\n",
    "\n",
    "filename_dict = FILENAME_DICT[LANG][\"filename_dict\"]\n",
    "for keyword in tqdm(filename_dict):\n",
    "    for filename in filename_dict[keyword]:\n",
    "        filename2keyword[filename] = keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3884f5-9968-4977-8402-63ebb8d1ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_from_textgrid(filename, sr=16_000, segment_length=0.7):\n",
    "    keyword = filename2keyword[filename]\n",
    "    keyword_basename = os.path.basename(filename)[:-4] + \"TextGrid\"\n",
    "\n",
    "    flag = False\n",
    "    for textgrid_filename in textgrid_filenames:\n",
    "        textgrid_basename = os.path.basename(textgrid_filename)\n",
    "        if keyword_basename == textgrid_basename:\n",
    "            flag = True\n",
    "            break\n",
    "\n",
    "    if flag:\n",
    "        speech_path = SPEECH_TEMPLATE.format(os.path.basename(filename)[:-5])\n",
    "        speech_wav, _ = librosa.load(speech_path, sr=sr)\n",
    "        speech_length = len(speech_wav) / sr\n",
    "        \n",
    "        words = textgrid.TextGrid.fromFile(textgrid_filename)[0]\n",
    "        target_word = filename.split(os.path.sep)[-2]\n",
    "        words_list = [word.mark for word in words]\n",
    "        segment_word = words[words_list.index(target_word)]\n",
    "        \n",
    "        minTime, maxTime = segment_word.minTime, segment_word.maxTime\n",
    "        delta_time = (maxTime - minTime)\n",
    "        if delta_time < segment_length:\n",
    "            delta_time = segment_length - delta_time\n",
    "            if delta_time > 0:\n",
    "                if minTime - delta_time > 0:\n",
    "                    minTime = minTime - delta_time / 2\n",
    "                else:\n",
    "                    minTime = 0.0\n",
    "\n",
    "                maxTime = minTime + segment_length                \n",
    "\n",
    "        \n",
    "        save_path = f\"./Processed_Keywords/{LANG}/{keyword}\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        save_path = f\"{save_path}/{os.path.basename(filename)[:-4]}wav\"\n",
    "        \n",
    "        keyword_wav = speech_wav[int(sr*minTime):int(sr*maxTime)]\n",
    "        scipy.io.wavfile.write(save_path, sr, keyword_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aad381-1287-4e7f-b9d7-f4493069d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkerPool(n_jobs=8) as pool:\n",
    "    results = pool.map(segment_from_textgrid, list(filename2keyword.keys()), progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669bd96-1588-4252-a653-352424f1b229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8c403-2699-4a84-a538-d7714514a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff823fc-c587-4cc4-a5af-1902b1393502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11fc2d11-efcc-4c5a-9528-0d0d9fd65bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from mpire import WorkerPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2708f48b-a4d0-473f-babd-7b44abfaa0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22521349"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = glob(\"../Data/audio/*/clips/*/*.opus\")\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffad6e30-8db1-4156-8293-dbd1ab2b9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty_file(filename):\n",
    "    size = os.path.getsize(filename)\n",
    "    if size < 100:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09047a-af2b-47d2-95ad-e95dbe1b9392",
   "metadata": {},
   "outputs": [],
   "source": [
    "with WorkerPool(n_jobs=16) as pool:\n",
    "    results = pool.map(check_empty_file, filenames, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93686d0f-31e5-440d-bf51-246c15c8d245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa268b-4f79-48eb-92dd-216b6638f6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bcf63e-2435-4e43-9efb-e7ada6a821fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e49f8f5d-a523-4e18-ad23-0272b2756bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f6abc7a70b4474b506c7862be741cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/851 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for folder in tqdm(BUFFER[\"fa\"][\"filename_dict\"]):\n",
    "    for filename in BUFFER[\"fa\"][\"filename_dict\"][folder]:\n",
    "        splited = filename.split(os.path.sep)\n",
    "\n",
    "        new_folder = f\"../Data/KeyWords/fa/clips/{splited[-2]}\"\n",
    "        new_filename = f\"../Data/KeyWords/fa/clips/{splited[-2]}/{splited[-1]}\"\n",
    "\n",
    "        os.makedirs(new_folder, exist_ok=True)\n",
    "        shutil.copy(filename, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929489d-8b22-4287-afd5-4ff017b419d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
