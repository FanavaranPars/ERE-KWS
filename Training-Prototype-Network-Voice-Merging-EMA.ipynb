{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dfa2c56-1c9f-407f-a0db-3c85d9333fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432b9a23-f1df-448e-8ac1-1d90dce7b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import top_k_accuracy_score, accuracy_score\n",
    "\n",
    "import re\n",
    "import hazm\n",
    "import unicodedata\n",
    "import Levenshtein\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from audiomentations import AddBackgroundNoise, AddBackgroundNoise, ApplyImpulseResponse, PitchShift, TimeStretch\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torchaudio import transforms as T\n",
    "from torch.optim import AdamW, Adam\n",
    "from transformers import get_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from resnet12 import resnet12, wide_resnet12\n",
    "from torch_ema import ExponentialMovingAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2328d89-2a4a-41e8-baba-77ae479c02de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85999ded-afa2-404e-b0d2-2bbd5721248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('FILENAME_DICT.json', 'r') as fp:\n",
    "    TRAIN_FILENAME_DICT = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3d2f0a-f834-4022-99e8-a2091017585c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e418674-d637-4546-9e6d-69ddd4ce2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = {}\n",
    "for folder in TRAIN_FILENAME_DICT[\"fa\"][\"folders\"]:\n",
    "    filenames = glob(f\"./Processed_Keywords/fa/{folder}/*.wav\")\n",
    "\n",
    "    if len(filenames) > 60:\n",
    "        buffer[folder] = filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa43c139-bcc7-4222-a1a7-b3b637439790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del TRAIN_FILENAME_DICT[\"fa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4640f760-0809-4b82-a9dc-169898991f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_FILENAME_DICT = {}\n",
    "VALID_FILENAME_DICT[\"fa\"] = {\n",
    "    \"filename_dict\" : buffer,\n",
    "    \"folders\" : list(buffer.keys()),\n",
    "    \"dataset_length\" : sum([len(buffer[folder]) for folder in buffer])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb86cce5-a4c5-449e-9ef0-f20fd7cef840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c434e4-3b45-4fac-a7df-6f09c12eaac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b457fe-fac4-48cf-9e7c-8132da62a751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b1d9da-4938-42a0-b190-7e35141ed51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAY = 10\n",
    "N_SUPPORT = 10\n",
    "N_UNKNOWN = 10\n",
    "N_QUERY = 25\n",
    "\n",
    "N_WAY_V = 1\n",
    "N_SUPPORT_V = 30\n",
    "N_UNKNOWN_V = 10\n",
    "N_QUERY_V = 30\n",
    "\n",
    "GAMMA = 3\n",
    "LAMBDA = 0.1\n",
    "\n",
    "\n",
    "WAV_LENGTH = 0.7\n",
    "SHIFT_LENGTH = 0.01\n",
    "N_MFCC = int(WAV_LENGTH / SHIFT_LENGTH)\n",
    "\n",
    "EMA_STEP = 10\n",
    "EMA_STEP_AFTER = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3105b9-e26f-46cc-ada6-ce74de16e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBatchSampler(Sampler):\n",
    "    def __init__(self, filename_dict, n_way=10, n_support=5, n_unkown=10, n_query=5, min_folder=20):\n",
    "        self.filename_dict = filename_dict\n",
    "        self.n_way = n_way\n",
    "        self.n_support = n_support\n",
    "        self.n_unkown = n_unkown\n",
    "        self.n_query = n_query\n",
    "        self.min_folder = min_folder\n",
    "\n",
    "        self.filter_lang()\n",
    "        self.LANG = list(self.filename_dict.keys())\n",
    "        \n",
    "        self.len_dataset = len(self)\n",
    "        self.calculate_probability()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for _ in range(self.len_dataset):\n",
    "            \n",
    "            random_lang = np.random.choice(self.LANG, size=1, p=self.LANG_PROBS)[0]\n",
    "            random_cluster = np.random.choice(self.filename_dict[random_lang][\"folders\"],\n",
    "                                              size=self.n_way + self.n_unkown,\n",
    "                                              replace=False,\n",
    "                                              p=self.filename_dict[random_lang][\"probs\"])\n",
    "\n",
    "            batch_support_filenames, batch_known_filenames, batch_unknown_filenames = [], [], []\n",
    "            for cluster in random_cluster[:self.n_way]:\n",
    "                known_filenames = np.random.choice(self.filename_dict[random_lang][\"filename_dict\"][cluster],\n",
    "                                                   size=self.n_support + self.n_query,\n",
    "                                                   replace=False)\n",
    "                \n",
    "                batch_support_filenames += known_filenames.tolist()[:self.n_support]\n",
    "                batch_known_filenames += known_filenames.tolist()[self.n_support:]\n",
    "\n",
    "\n",
    "            for cluster in random_cluster[self.n_way:]:\n",
    "                unknown_filenames = np.random.choice(self.filename_dict[random_lang][\"filename_dict\"][cluster],\n",
    "                                                     size=self.n_query,\n",
    "                                                     replace=False)\n",
    "                \n",
    "                batch_unknown_filenames += unknown_filenames.tolist()\n",
    "\n",
    "            batch_filenames = batch_support_filenames + batch_known_filenames + batch_unknown_filenames\n",
    "                \n",
    "            yield batch_filenames\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        n_data = sum([self.filename_dict[lang][\"dataset_length\"] for lang in self.LANG])        \n",
    "        return int(n_data // (self.n_way * self.n_support + (self.n_way + self.n_unkown) * self.n_query))\n",
    "\n",
    "\n",
    "    def calculate_probability(self, temp=1/2):\n",
    "        for lang in self.LANG:\n",
    "            folders = self.filename_dict[lang][\"folders\"]\n",
    "            \n",
    "            prob = []\n",
    "            for folder in self.filename_dict[lang][\"filename_dict\"]:\n",
    "                prob.append(len(self.filename_dict[lang][\"filename_dict\"][folder]))\n",
    "                \n",
    "            prob = np.array(prob)\n",
    "            prob = prob / prob.sum()\n",
    "            prob = prob ** temp\n",
    "            prob = prob / prob.sum()\n",
    "            prob = prob.tolist()\n",
    "\n",
    "            self.filename_dict[lang][\"probs\"] = prob\n",
    "\n",
    "        \n",
    "        lang_prob = []\n",
    "        for lang in self.LANG:\n",
    "            lang_prob.append(self.filename_dict[lang][\"dataset_length\"])\n",
    "        \n",
    "        lang_prob = np.array(lang_prob)\n",
    "        lang_prob = lang_prob / lang_prob.sum()\n",
    "        lang_prob = lang_prob ** temp\n",
    "        lang_prob = lang_prob / lang_prob.sum()\n",
    "        lang_prob = lang_prob.tolist()\n",
    "\n",
    "        self.LANG_PROBS = lang_prob\n",
    "    \n",
    "\n",
    "    def filter_lang(self):\n",
    "        delete_lang = []\n",
    "        for lang in self.filename_dict.keys():\n",
    "            if len(self.filename_dict[lang][\"folders\"]) < self.min_folder:\n",
    "                delete_lang.append(lang)\n",
    "                \n",
    "        for lang in delete_lang:\n",
    "            del self.filename_dict[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20345b06-c0c6-46ff-b5d4-c9c71a1272d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidBatchSampler(Sampler):\n",
    "    def __init__(self, filename_dict, n_way=1, n_support=5, n_unkown=10, n_query=5, min_folder=20):\n",
    "        self.filename_dict = filename_dict\n",
    "        self.n_way = n_way\n",
    "        self.n_support = n_support\n",
    "        self.n_unkown = n_unkown\n",
    "        self.n_query = n_query\n",
    "        self.min_folder = min_folder\n",
    "\n",
    "        self.filter_lang()\n",
    "        self.LANG = list(self.filename_dict.keys())\n",
    "        \n",
    "        self.len_dataset = len(self)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \n",
    "        for lang in self.LANG:\n",
    "            folders = self.filename_dict[lang][\"folders\"]\n",
    "            for folder in folders:\n",
    "                folders_ = folders.copy()\n",
    "                folders_.remove(folder)\n",
    "\n",
    "                batch_known_filenames = np.random.choice(self.filename_dict[lang][\"filename_dict\"][folder],\n",
    "                                                         size=self.n_support + self.n_query,\n",
    "                                                         replace=False).tolist()\n",
    "\n",
    "                \n",
    "                random_clusters = np.random.choice(folders_,\n",
    "                                                   size=self.n_unkown,\n",
    "                                                   replace=False)\n",
    "                \n",
    "                batch_unknown_filenames = []\n",
    "                for cluster in random_clusters:\n",
    "                    unknown_filenames = np.random.choice(self.filename_dict[lang][\"filename_dict\"][cluster],\n",
    "                                                         size=self.n_query,\n",
    "                                                         replace=False)\n",
    "                    \n",
    "                    batch_unknown_filenames += unknown_filenames.tolist()\n",
    "    \n",
    "                batch_filenames = batch_known_filenames + batch_unknown_filenames\n",
    "                yield batch_filenames\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(self.filename_dict[lang][\"folders\"]) for lang in self.LANG])\n",
    "    \n",
    "\n",
    "    def filter_lang(self):\n",
    "        delete_lang = []\n",
    "        for lang in self.filename_dict.keys():\n",
    "            if len(self.filename_dict[lang][\"folders\"]) < self.min_folder:\n",
    "                delete_lang.append(lang)\n",
    "                \n",
    "        for lang in delete_lang:\n",
    "            del self.filename_dict[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff9335e-2910-4f39-a330-95c02c13c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSCBatchSampler(Sampler):\n",
    "    def __init__(self, valid_filenamedict, test_filenamedict, n_support=5, n_unkown=10, n_query=5, n_repeat=10):\n",
    "        self.valid_filenamedict = valid_filenamedict\n",
    "        self.test_filenamedict = test_filenamedict\n",
    "        self.n_support = n_support\n",
    "        self.n_unkown = n_unkown\n",
    "        self.n_query = n_query\n",
    "        self.n_repeat = n_repeat\n",
    "        \n",
    "        self.len_dataset = len(self)\n",
    "        \n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.n_repeat):\n",
    "            for folder in self.test_filenamedict:\n",
    "                folders = list(self.test_filenamedict.keys())\n",
    "                folders.remove(folder)\n",
    "            \n",
    "                batch_support_filenames = np.random.choice(self.valid_filenamedict[folder],\n",
    "                                                           size=self.n_support,\n",
    "                                                           replace=False).tolist()\n",
    "            \n",
    "                \n",
    "                target_folder_filenames = self.test_filenamedict[folder].copy()\n",
    "                n_query_batch = len(target_folder_filenames) // self.n_query\n",
    "                \n",
    "                for idx in range(n_query_batch):\n",
    "                    batch_known_filenames = target_folder_filenames[idx*self.n_query:(idx+1)*self.n_query]\n",
    "            \n",
    "                    random_clusters = np.random.choice(folders,\n",
    "                                                       size=self.n_unkown,\n",
    "                                                       replace=False)\n",
    "            \n",
    "                    batch_unknown_filenames = []\n",
    "                    for cluster in random_clusters:\n",
    "                        unknown_filenames = np.random.choice(self.test_filenamedict[cluster],\n",
    "                                                             size=self.n_query,\n",
    "                                                             replace=False)\n",
    "                        \n",
    "                        batch_unknown_filenames += unknown_filenames.tolist()\n",
    "            \n",
    "                    batch_filenames = batch_support_filenames + batch_known_filenames + batch_unknown_filenames\n",
    "            \n",
    "                    yield batch_filenames\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        n_batch = 0\n",
    "        for folder in self.test_filenamedict:\n",
    "            n_batch += len(self.test_filenamedict[folder]) // self.n_query\n",
    "        return n_batch * self.n_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a1dd7-0a50-418c-8c43-aada6d840af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d44004-3c85-4903-80ee-4c40bfa8a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = CustomBatchSampler(TRAIN_FILENAME_DICT,\n",
    "                                   n_way=N_WAY,\n",
    "                                   n_support=N_SUPPORT,\n",
    "                                   n_unkown=N_UNKNOWN,\n",
    "                                   n_query=N_QUERY)\n",
    "\n",
    "valid_sampler = ValidBatchSampler(VALID_FILENAME_DICT,\n",
    "                                  n_way=N_WAY_V,\n",
    "                                  n_support=N_SUPPORT_V,\n",
    "                                  n_unkown=N_UNKNOWN_V,\n",
    "                                  n_query=N_QUERY_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef90741-dce1-4464-8f81-34a7847c581c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0696ae2eb6d46a8a374337384a8a7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12461 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36fd596b2af452da40e0d8b3abc7d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for a in tqdm(train_sampler):\n",
    "    break\n",
    "\n",
    "for a in tqdm(valid_sampler):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d161c-a53d-4688-8334-1ef6f4da4bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22711d64-1849-41ed-a13c-c6fe9317b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemovePad(object):\n",
    "    def __init__(self, thershold=0.05, fs=16_000, segment_move=0.025):\n",
    "        self.thershold = thershold\n",
    "        segment_move = int(fs * segment_move)\n",
    "        self.window = np.ones(segment_move) / int(segment_move/2)\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        moving_average_wav = np.convolve(np.abs(wav), self.window, mode='same')\n",
    "        cutoff = np.where(moving_average_wav > self.thershold)[0]\n",
    "\n",
    "        if len(cutoff) < 2:\n",
    "            return wav\n",
    "\n",
    "        return wav[cutoff[0]:cutoff[-1]]\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self):\n",
    "        self.EPS = np.finfo(float).eps\n",
    "        \n",
    "    def __call__(self, wav):\n",
    "        samples_99_percentile = np.percentile(np.abs(wav), 99.9)\n",
    "        normalized_samples = wav / (samples_99_percentile + self.EPS)\n",
    "        normalized_samples = np.clip(normalized_samples, -1, 1)\n",
    "        return normalized_samples\n",
    "\n",
    "\n",
    "class PadTrimWav(object):\n",
    "    def __init__(self, segment_length=1.0, fs=16_000):\n",
    "        self.segment_length = int(fs * segment_length)\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        len_wav = len(wav)\n",
    "\n",
    "        zeros = np.zeros(self.segment_length, dtype=np.float32)\n",
    "        if len_wav < self.segment_length:\n",
    "            start_point = (self.segment_length - len_wav) // 2\n",
    "            zeros[start_point:start_point+len_wav] = wav\n",
    "        else:\n",
    "            start_point = (len_wav -  self.segment_length) // 2\n",
    "            zeros = wav[start_point:start_point+self.segment_length]\n",
    "\n",
    "        return zeros\n",
    "\n",
    "\n",
    "class RandomPadTrimMFCC(object):\n",
    "    def __init__(self, segment_shape=(40,100)):\n",
    "        self.segment_shape = segment_shape\n",
    "\n",
    "    def __call__(self, mfcc):\n",
    "        mfcc = mfcc.numpy()\n",
    "        mfcc_shape = mfcc.shape\n",
    "\n",
    "        zeros = np.zeros(self.segment_shape, dtype=np.float32)\n",
    "        if mfcc_shape[1] <= self.segment_shape[1]:\n",
    "            random_point = np.random.randint(0, self.segment_shape[1] - mfcc_shape[1] + 1)\n",
    "            zeros[:, random_point:random_point+mfcc_shape[1]] = mfcc\n",
    "        else:\n",
    "            random_point = np.random.randint(0, mfcc_shape[1] - self.segment_shape[1] + 1)\n",
    "            zeros = mfcc[:, random_point:random_point+self.segment_shape[1]]\n",
    "\n",
    "        return zeros\n",
    "\n",
    "\n",
    "class PadTrimMFCC(object):\n",
    "    def __init__(self, segment_shape=(40,100)):\n",
    "        self.segment_shape = segment_shape\n",
    "\n",
    "    def __call__(self, mfcc):\n",
    "        mfcc = mfcc.numpy()\n",
    "        mfcc_shape = mfcc.shape\n",
    "\n",
    "        zeros = np.zeros(self.segment_shape, dtype=np.float32)\n",
    "        if mfcc_shape[1] <= self.segment_shape[1]:\n",
    "            start_point = (self.segment_shape[1] - mfcc_shape[1]) // 2\n",
    "            zeros[:, start_point:start_point+mfcc_shape[1]] = mfcc\n",
    "        else:\n",
    "            start_point = (mfcc_shape[1] - self.segment_shape[1]) // 2\n",
    "            zeros = mfcc[:, start_point:start_point+self.segment_shape[1]]\n",
    "\n",
    "        return zeros\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, wav):\n",
    "        return torch.from_numpy(wav)\n",
    "\n",
    "\n",
    "class MFCC(object):\n",
    "    def __init__(self, fs=16_000, n_fft=480, hop_length=160, n_mels=128, n_mfcc=41):\n",
    "        \n",
    "        self.mfcc = T.MFCC(\n",
    "            sample_rate=fs,\n",
    "            n_mfcc=n_mfcc,\n",
    "            melkwargs={\n",
    "                \"n_fft\": n_fft,\n",
    "                \"n_mels\": n_mels,\n",
    "                \"hop_length\": hop_length,\n",
    "                \"mel_scale\": \"htk\",\n",
    "            },\n",
    "        )\n",
    "        \n",
    "    def __call__(self, wav):\n",
    "        mfcc = self.mfcc(wav)[1:]\n",
    "        mfcc = mfcc - mfcc.mean(axis=1, keepdims=True)\n",
    "        return mfcc / 100.0\n",
    "\n",
    "\n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        for transform in self.transforms:\n",
    "            wav = transform(wav)\n",
    "\n",
    "        return wav\n",
    "\n",
    "\n",
    "\n",
    "class AugCompose:\n",
    "    def __init__(self, aug_list, aug_prob, p, n_apply, sample_rate=16_000):\n",
    "        self.aug_list = aug_list\n",
    "        self.aug_prob = np.array(aug_prob) / np.sum(aug_prob)\n",
    "        self.p = p\n",
    "        self.n_apply = n_apply\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "        self.range = list(range(len(aug_prob)))\n",
    "        \n",
    "    def __call__(self, wav):\n",
    "        \n",
    "        if random.random() < self.p:\n",
    "            indexs = random.choices(self.range, self.aug_prob)[0]\n",
    "            indexs = np.random.choice(self.range, size=self.n_apply, replace=False, p=self.aug_prob)\n",
    "            \n",
    "            for index in indexs:\n",
    "                wav = self.aug_list[index](wav, sample_rate=self.sample_rate)\n",
    "        \n",
    "        return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bad26c2f-8ebf-4cfd-b792-2e030668f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadDataset(Dataset):\n",
    "    def __init__(self, fs=16_000, transforms=None):\n",
    "        self.fs = fs\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav, _ = librosa.load(idx, sr=self.fs)\n",
    "        \n",
    "        if self.transforms:\n",
    "            wav = self.transforms(wav)\n",
    "\n",
    "        return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2d3ee-87e6-40d5-850e-d592e6125a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b84cd9-e3e7-4c80-a3b4-a333d4c99e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_filenames = shuffle(glob(\"../Data/cv-corpus/fa/clips/*.mp3\"), random_state=42)\n",
    "noise_filenames = shuffle(glob(\"../Data/RIR_Noise/Noise/*.wav\"), random_state=42)\n",
    "rir_filenames = shuffle(glob(\"../Data/RIR_Noise/RIR/*.wav\"), random_state=42)\n",
    "\n",
    "\n",
    "AUGMENTATION = AugCompose(\n",
    "    [\n",
    "        AddBackgroundNoise(speech_filenames[:512], min_snr_in_db=10.0, max_snr_in_db=20.0, lru_cache_size=512, p=1.0),\n",
    "        AddBackgroundNoise(noise_filenames[:512], min_snr_in_db=10.0, max_snr_in_db=20.0, lru_cache_size=512, p=1.0),\n",
    "        ApplyImpulseResponse(rir_filenames[:512], lru_cache_size=512, p=1.0),\n",
    "        PitchShift(min_semitones=-3.0, max_semitones=3.0, p=1.0),\n",
    "        TimeStretch(min_rate=0.75, max_rate=1.25, p=1.0)\n",
    "    ],\n",
    "    aug_prob=[1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "    p=0.5, n_apply=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "550fdd85-40a0-4f7d-9eac-ebb0d507db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        PadTrimWav(segment_length=WAV_LENGTH),\n",
    "        AUGMENTATION,\n",
    "        Normalize(),\n",
    "        ToTensor(),\n",
    "        MFCC(),\n",
    "        RandomPadTrimMFCC(segment_shape=(40,N_MFCC)),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "valid_transforms = Compose(\n",
    "    [\n",
    "        PadTrimWav(segment_length=WAV_LENGTH),\n",
    "        Normalize(),\n",
    "        ToTensor(),\n",
    "        MFCC(),\n",
    "        PadTrimMFCC(segment_shape=(40,N_MFCC)),\n",
    "        ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = ReadDataset(transforms=train_transforms)\n",
    "valid_dataset = ReadDataset(transforms=valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97731a4d-65fd-45bf-81c8-9fda68bf97c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac1aff1-d883-4e1f-91f1-956ce7a5471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_collate_fn(batch_wavs):\n",
    "    batch_labels = []\n",
    "    for i in range(N_WAY):\n",
    "        batch_labels += [i] * N_QUERY\n",
    "        \n",
    "    batch_labels += [N_WAY] * (N_UNKNOWN * N_QUERY)\n",
    "    batch_labels = F.one_hot(torch.LongTensor(batch_labels))\n",
    "\n",
    "    batch_wavs = torch.stack(batch_wavs)\n",
    "    return batch_wavs, batch_labels\n",
    "\n",
    "\n",
    "def valid_collate_fn(batch_wavs):\n",
    "    batch_labels = []\n",
    "    for i in range(N_WAY_V):\n",
    "        batch_labels += [i] * N_QUERY_V\n",
    "        \n",
    "    batch_labels += [N_WAY_V] * (N_UNKNOWN_V * N_QUERY_V)\n",
    "    batch_labels = F.one_hot(torch.LongTensor(batch_labels))\n",
    "\n",
    "    batch_wavs = torch.stack(batch_wavs)\n",
    "    return batch_wavs, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b66375c1-d260-46c8-99dc-f5ed8a6ac084",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_sampler=train_sampler,\n",
    "                              num_workers=20,\n",
    "                              collate_fn=train_collate_fn,\n",
    "                              prefetch_factor=2)\n",
    "\n",
    "valid_dataloader = DataLoader(valid_dataset,\n",
    "                              batch_sampler=valid_sampler,\n",
    "                              num_workers=20,\n",
    "                              collate_fn=valid_collate_fn,\n",
    "                              prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b73eee2-4b40-4f9e-acb3-2a8c513c8d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c18cb783e9441b2b750310a90f7fde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12461 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 40, 70]) torch.Size([500, 11])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5aa503ba1254af19e5db998844b553a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y in tqdm(train_dataloader):\n",
    "    break\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "for x, y in tqdm(valid_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f1c90-884d-4257-bf0a-ccee71dff1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20517542-3ae5-4947-acd6-6c78dc546f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f81f1f1-62d9-44ff-bee6-968135379d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da05413c-ceeb-4565-ba09-5e8e9290ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wide_resnet12(normalize=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c2f37ae-3ccd-4bbc-9455-80b2b7b962b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModel(torch.nn.Module):\n",
    "    def __init__(self, n_input=640, n_hidden=32):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(n_input, n_hidden, bias=False)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(n_hidden, n_hidden, bias=False)\n",
    "        self.linear3 = torch.nn.Linear(n_hidden, n_input, bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x, _ = torch.max(x, axis=0, keepdim=True)\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "dummy_model = DummyModel()\n",
    "dummy_model = dummy_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d759815-d16f-45d3-9236-2c4da14d21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_model = ExponentialMovingAverage(model.parameters(), decay=0.995)\n",
    "ema_dummy_model = ExponentialMovingAverage(dummy_model.parameters(), decay=0.9998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fcc9d7c-e615-461f-a429-a4fab263fe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters : 12.465024 M\n"
     ]
    }
   ],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad) + sum(p.numel() for p in dummy_model.parameters() if p.requires_grad)\n",
    "print(f\"Model parameters : {pytorch_total_params / 10 ** 6} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf562f-5ddc-4419-a348-5a62352e3ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef147bd4-5961-468d-93f8-bdf640dc135f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "585b8167-f551-4059-acab-979e0e5f6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability(outputs, n_way, n_support):\n",
    "    output_supports = outputs[:n_way*n_support]\n",
    "    output_query = outputs[n_way*n_support:]\n",
    "    \n",
    "    support_centers = rearrange(output_supports, \"(w s) e -> w s e\", s=n_support).mean(axis=1)\n",
    "    unknown_center = dummy_model(support_centers)\n",
    "    \n",
    "    centers = torch.concat([support_centers, unknown_center], axis=0)\n",
    "    \n",
    "    center_weights = torch.ones((1, centers.shape[0]))\n",
    "    center_weights[:,-1] = GAMMA\n",
    "    center_weights = center_weights.to(device)\n",
    "    \n",
    "    distances = torch.cdist(output_query, centers, p=2)\n",
    "    distances = -distances / center_weights\n",
    "    likelihood = torch.exp(distances) / torch.exp(distances).sum(axis=1, keepdim=True)\n",
    "    \n",
    "    return likelihood\n",
    "\n",
    "\n",
    "def loss_fn(outputs, targets, n_way, n_support, n_query):\n",
    "    likelihood = calculate_probability(outputs, n_way, n_support)\n",
    "    \n",
    "    neg_prob = -torch.log(likelihood)\n",
    "    neg_prob = neg_prob * targets\n",
    "    \n",
    "    ce_loss_known = torch.sum(neg_prob[:n_way*n_query])\n",
    "    ce_loss_unknown = torch.sum(neg_prob[n_way*n_query:])\n",
    "    \n",
    "    return ce_loss_known, ce_loss_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37a3a9-574f-4486-9006-207810a9d4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564cbfe-fb6b-4290-841f-233bac70be00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45861110-a9dc-47e3-972e-56964380f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "#optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.01) ######### weight decay\n",
    "optimizer = Adam(list(model.parameters()) + list(dummy_model.parameters()), lr=2e-4)\n",
    "#lr_scheduler = get_scheduler(\n",
    "#     \"linear\",\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=int(0.1*num_training_steps),\n",
    "#     num_training_steps=num_training_steps,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f7cff43-f279-4860-b18d-13bba6613346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def top_k_score(y_true, y_pred, k=1):\n",
    "#    y_pred = torch.argsort(y_pred, axis=1, descending=True)[:,:k]\n",
    "#    y_true = torch.unsqueeze(y_true, 1)\n",
    "#\n",
    "#    return torch.sum(y_pred == y_true).item()\n",
    "\n",
    "\n",
    "def evaluate(Delta=0.5):\n",
    "    known_acc = []\n",
    "    unknown_acc = []\n",
    "    val_loss = []\n",
    "    val_known_loss = []\n",
    "    val_unknown_loss = []\n",
    "    \n",
    "    \n",
    "    LIKELIHOODS = []\n",
    "    with ema_model.average_parameters():\n",
    "        with ema_dummy_model.average_parameters():\n",
    "            model.eval()\n",
    "            dummy_model.eval()\n",
    "            \n",
    "            for batch_x, batch_y in tqdm(valid_dataloader):\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(torch.unsqueeze(batch_x, 1))\n",
    "                    \n",
    "                    loss_known, loss_unknown = loss_fn(outputs, batch_y, N_WAY_V, N_SUPPORT_V, N_QUERY_V)\n",
    "                    loss = LAMBDA * loss_known + loss_unknown\n",
    "                    \n",
    "                    val_loss.append(loss.item())\n",
    "                    val_known_loss.append(loss_known.item())\n",
    "                    val_unknown_loss.append(loss_unknown.item())\n",
    "            \n",
    "                    likelihood = calculate_probability(outputs, N_WAY_V, N_SUPPORT_V)\n",
    "                    LIKELIHOODS.append(likelihood)\n",
    "            \n",
    "                    #known_acc.append(torch.sum(likelihood[:N_WAY_V*N_QUERY_V,1] < Delta).cpu().item() / (N_WAY_V*N_QUERY_V))\n",
    "                    #unknown_acc.append(torch.sum(likelihood[N_WAY_V*N_QUERY_V:,1] >= Delta).cpu().item() / (likelihood.size(0) - N_WAY_V*N_QUERY_V))\n",
    "            \n",
    "            model.train()\n",
    "            dummy_model.train()\n",
    "\n",
    "    \n",
    "    A = rearrange(torch.stack(LIKELIHOODS, axis=0)[:,:N_WAY_V*N_QUERY_V,:], \"a b c -> (a b) c\")\n",
    "    B = rearrange(torch.stack(LIKELIHOODS, axis=0)[:,N_WAY_V*N_QUERY_V:,:], \"a b c -> (a b) c\")\n",
    "    \n",
    "    known_acc, unknown_acc = [], []\n",
    "    for delta in np.arange(0,1,0.001):\n",
    "        known = torch.sum(A[:,1] < delta) / A.shape[0]\n",
    "        unknown = torch.sum(B[:,1] > delta) / B.shape[0]\n",
    "    \n",
    "        known_acc.append(known.item())\n",
    "        unknown_acc.append(unknown.item())\n",
    "\n",
    "    mul_prob = np.array(known_acc) * np.array(unknown_acc)\n",
    "    MAX, IDX = np.max(mul_prob), np.argmax(mul_prob)\n",
    "\n",
    "    \n",
    "    \n",
    "    #known_acc = np.mean(known_acc)\n",
    "    #unknown_acc = np.mean(unknown_acc)\n",
    "    known_acc = known_acc[IDX]\n",
    "    unknown_acc = unknown_acc[IDX]\n",
    "    \n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_known_loss = np.mean(val_known_loss)\n",
    "    val_unknown_loss = np.mean(val_unknown_loss)\n",
    "\n",
    "    return known_acc, unknown_acc, val_loss, val_known_loss, val_unknown_loss, IDX / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d85f43-247f-4d26-b0b4-71bb6f1102b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8837baae-cb75-4457-a29c-4ea3a132698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## resume training\n",
    "#checkpoint = torch.load(\"./RESULTS/WithEMA/pretrained_model_624000.pth\")\n",
    "\n",
    "#step_count = checkpoint[\"steps\"]\n",
    "#model.load_state_dict(checkpoint['model'])\n",
    "#dummy_model.load_state_dict(checkpoint['dummy_model'])\n",
    "#optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "#ema_model.load_state_dict(checkpoint['ema_model'])\n",
    "#ema_dummy_model.load_state_dict(checkpoint['ema_dummy_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "682b3ce5-8b06-484f-8066-94890837e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ema_model.copy_to(model.parameters())\n",
    "#ema_dummy_model.copy_to(dummy_model.parameters())\n",
    "\n",
    "#torch.save({\n",
    "#    \"model\": model.state_dict(),\n",
    "#    \"dummy_model\" : dummy_model.state_dict(),\n",
    "#}, f\"SAVED_MODELS/WideResNet12WithEMA.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02f363-e10e-489d-92cc-13dd9ee30c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0e76482-e55c-4964-a23e-798c2d0b7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = []\n",
    "#for _ in tqdm(range(10)):\n",
    "#    results.append(evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f44b871-bf1c-4410-88a9-b1c6d0d5f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Few_Shot = {30 : results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cc130884-0320-48ac-b233-41549a520a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Few_Shot_30.json', 'w') as fp:\n",
    "#    json.dump(Few_Shot, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816224e-dca0-484e-96b1-5789915a3b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1eb0684f-c913-45f4-aa08-ed7a86fff865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_results_mean, all_results_std = [], []\n",
    "#for i in [1,5,10,20,30]:\n",
    "#    with open(f'Few_Shot_{i}.json', 'r') as fp:\n",
    "#        results = json.load(fp)\n",
    "#\n",
    "#    results = np.array(results[str(i)])\n",
    "#    all_results_mean.append(results.mean(axis=0))\n",
    "#    all_results_std.append(results.std(axis=0))\n",
    "#    \n",
    "#all_results_mean = np.stack(all_results_mean, axis=0)\n",
    "#all_results_std = np.stack(all_results_std, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "883a2d58-6df1-48a3-895d-b4e3d63b8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.errorbar([1,5,10,20,30], all_results_mean[:,0], all_results_std[:,0])\n",
    "#plt.errorbar([1,5,10,20,30], all_results_mean[:,1], all_results_std[:,1])\n",
    "\n",
    "#plt.xlabel(\"Number of Samples\")\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "#plt.grid()\n",
    "#plt.legend([\"Known\", \"Unknown\"])\n",
    "#plt.savefig(\"Few_Shot_Accuracy.jpg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aa28f864-e301-476d-b521-c1ae652672bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.errorbar([1,5,10,20,30], all_results_mean[:,-1], all_results_std[:,-1])\n",
    "\n",
    "#plt.xlabel(\"Number of Samples\")\n",
    "#plt.ylabel(\"Delta\")\n",
    "#plt.grid()\n",
    "#plt.savefig(\"Few_Shot_Delta.jpg\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf52f2-7f29-4774-a26a-7b731f0dec6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b2506-780b-48ef-a830-4b42500d046c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd54fcb-6973-469d-bfd1-5cbc5f29fe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94c655-76ab-4ce4-bef9-27110796feed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383675c9a09c49b4b85c6d91da36ffb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcc0cfd3df841d8a050615c4761dcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458c46a6faba401d9b94b647f6d9453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee399af34418424f865c95c93730ebca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e598eb0e7e8451eac9c97857019ee99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d6e5d531784366ab05d53544cf6870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148db64b5e4d48938754a9f16e647f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e193a81020e4bce9b6c70add6b77fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac08442c356429984c27423c7fc74de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6ce8ee79e5486b8cc60b94ee380314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"checkpoints\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "writer = SummaryWriter(\"./runs/word_spotting\")\n",
    "progress_bar_train = tqdm(range(num_training_steps))\n",
    "#progress_bar_train.update(step_count)\n",
    "\n",
    "LOSS_SHOW_STEP = 500\n",
    "SAVE_STEP = 6_000\n",
    "EVAL_STEP = 3_000\n",
    "\n",
    "model.train()\n",
    "dummy_model.train()\n",
    "\n",
    "step_count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss, train_known_loss, train_unknown_loss = [], [], []\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        outputs = model(torch.unsqueeze(batch_x, 1))\n",
    "        \n",
    "        loss_known, loss_unknown = loss_fn(outputs, batch_y, N_WAY, N_SUPPORT, N_QUERY)\n",
    "        loss = LAMBDA * loss_known + loss_unknown\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        train_known_loss.append(loss_known.item())\n",
    "        train_unknown_loss.append(loss_unknown.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if step_count > EMA_STEP_AFTER:\n",
    "            if step_count % EMA_STEP == 0:\n",
    "                ema_model.update()\n",
    "                ema_dummy_model.update()\n",
    "        \n",
    "        progress_bar_train.update(1)\n",
    "\n",
    "\n",
    "        step_count += 1\n",
    "        if (step_count % LOSS_SHOW_STEP == 0):\n",
    "            writer.add_scalar('Loss/Train', np.mean(train_loss), step_count)\n",
    "            writer.add_scalar('Loss/Train_Known', np.mean(train_known_loss), step_count)\n",
    "            writer.add_scalar('Loss/Train_Unknown', np.mean(train_unknown_loss), step_count)\n",
    "            train_loss, train_known_loss, train_unknown_loss = [], [], []\n",
    "\n",
    "\n",
    "        if (step_count % SAVE_STEP == 0):\n",
    "            torch.save({\n",
    "                \"steps\": step_count,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"dummy_model\" : dummy_model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"ema_model\": ema_model.state_dict(),\n",
    "                \"ema_dummy_model\" : ema_dummy_model.state_dict(),\n",
    "                #\"scheduler\": lr_scheduler.state_dict(),\n",
    "            }, f\"{output_dir}/pretrained_model_{step_count}.pth\")\n",
    "\n",
    "\n",
    "        if (step_count % EVAL_STEP == 0):            \n",
    "            known_acc, unknown_acc, val_loss, val_known_loss, val_unknown_loss, delta = evaluate()\n",
    "            \n",
    "            writer.add_scalar('Accuracy/Known', known_acc, step_count)\n",
    "            writer.add_scalar('Accuracy/Unknown', unknown_acc, step_count)\n",
    "            writer.add_scalar('Loss/Val', val_loss, step_count)\n",
    "            writer.add_scalar('Loss/Val_Known', val_known_loss, step_count)\n",
    "            writer.add_scalar('Loss/Val_Unknown', val_unknown_loss, step_count)\n",
    "            writer.add_scalar('Delta/Delta', delta, step_count)\n",
    "\n",
    "\n",
    "        if step_count == num_training_steps:\n",
    "            break\n",
    "\n",
    "\n",
    "torch.save({\n",
    "    \"steps\": step_count,\n",
    "    \"model\": model.state_dict(),\n",
    "    \"dummy_model\" : dummy_model.state_dict(),\n",
    "    \"optimizer\": optimizer.state_dict(),\n",
    "    \"ema_model\": ema_model.state_dict(),\n",
    "    \"ema_dummy_model\" : ema_dummy_model.state_dict(),\n",
    "    #\"scheduler\": lr_scheduler.state_dict(),\n",
    "}, f\"{output_dir}/pretrained_model_{step_count}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee832ed9-d3f0-40ec-8d33-5f7edc31291f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701d7a4-97a0-46da-8f1f-d490eb5b5c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5abdee8-ac2a-4297-bf4e-53e88d7c4a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5996cadb-8eba-4b86-81f8-e0384e6702cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_known_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m val_unknown_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     10\u001b[0m dummy_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     12\u001b[0m LIKELIHOODS \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "Delta = 0.8\n",
    "\n",
    "known_acc = []\n",
    "unknown_acc = []\n",
    "val_loss = []\n",
    "val_known_loss = []\n",
    "val_unknown_loss = []\n",
    "\n",
    "model.eval()\n",
    "dummy_model.eval()\n",
    "\n",
    "LIKELIHOODS = []\n",
    "for batch_x, batch_y in tqdm(valid_dataloader):\n",
    "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.unsqueeze(batch_x, 1))\n",
    "        \n",
    "        loss_known, loss_unknown = loss_fn(outputs, batch_y, N_WAY_V, N_SUPPORT_V, N_QUERY_V)\n",
    "        loss = LAMBDA * loss_known + loss_unknown\n",
    "        \n",
    "        val_loss.append(loss.item())\n",
    "        val_known_loss.append(loss_known.item())\n",
    "        val_unknown_loss.append(loss_unknown.item())\n",
    "\n",
    "        likelihood = calculate_probability(outputs, N_WAY_V, N_SUPPORT_V)\n",
    "        LIKELIHOODS.append(likelihood)\n",
    "\n",
    "        \n",
    "        known_acc.append(torch.sum(likelihood[:N_WAY_V*N_QUERY_V,1] < Delta).cpu().item() / (N_WAY_V*N_QUERY_V))\n",
    "        unknown_acc.append(torch.sum(likelihood[N_WAY_V*N_QUERY_V:,1] >= Delta).cpu().item() / (likelihood.size(0) - N_WAY_V*N_QUERY_V))\n",
    "\n",
    "known_acc = np.mean(known_acc)\n",
    "unknown_acc = np.mean(unknown_acc)\n",
    "val_loss = np.mean(val_loss)\n",
    "val_known_loss = np.mean(val_known_loss)\n",
    "val_unknown_loss = np.mean(val_unknown_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e87c4d9-d202-4a9e-b55e-0b48d6f6e341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [], [], [], [])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_acc, unknown_acc, val_loss, val_known_loss, val_unknown_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47b575-b911-4733-8458-80df82a4dd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395fdda-adc4-45c0-92ae-988d5f3967c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfe3d8cb-756a-4ca8-97fa-c1117b47b101",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LIKELIHOODS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m A \u001b[38;5;241m=\u001b[39m rearrange(torch\u001b[38;5;241m.\u001b[39mstack(\u001b[43mLIKELIHOODS\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[:,:N_WAY_V\u001b[38;5;241m*\u001b[39mN_QUERY_V,:], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma b c -> (a b) c\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m B \u001b[38;5;241m=\u001b[39m rearrange(torch\u001b[38;5;241m.\u001b[39mstack(LIKELIHOODS, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[:,N_WAY_V\u001b[38;5;241m*\u001b[39mN_QUERY_V:,:], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma b c -> (a b) c\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m A\u001b[38;5;241m.\u001b[39mshape, B\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LIKELIHOODS' is not defined"
     ]
    }
   ],
   "source": [
    "A = rearrange(torch.stack(LIKELIHOODS, axis=0)[:,:N_WAY_V*N_QUERY_V,:], \"a b c -> (a b) c\")\n",
    "B = rearrange(torch.stack(LIKELIHOODS, axis=0)[:,N_WAY_V*N_QUERY_V:,:], \"a b c -> (a b) c\")\n",
    "\n",
    "A.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86c8b6f0-f2d4-4a71-9bbf-a5c7e9b7f1a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m known_acc, un_known_acc \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m delta \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0.001\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     known \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mA\u001b[49m[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m delta) \u001b[38;5;241m/\u001b[39m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     unknown \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(B[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m delta) \u001b[38;5;241m/\u001b[39m B\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m     known_acc\u001b[38;5;241m.\u001b[39mappend(known\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "known_acc, un_known_acc = [], []\n",
    "for delta in np.arange(0,1,0.001):\n",
    "    known = torch.sum(A[:,1] < delta) / A.shape[0]\n",
    "    unknown = torch.sum(B[:,1] > delta) / B.shape[0]\n",
    "\n",
    "    known_acc.append(known.item())\n",
    "    un_known_acc.append(unknown.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96900d9-a4ab-4fc8-b76f-ba3b24f3b70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04937e0f-12f1-497d-879a-be2320c4830f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1000,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 10-shot, 1 way, 30 query, 10 random unknown\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_acc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0.001\u001b[39m), un_known_acc)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/pyplot.py:3590\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3584\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3594\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3595\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1724\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1724\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1000,) and (0,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10-shot, 1 way, 30 query, 10 random unknown\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(0,1,0.001), known_acc)\n",
    "plt.plot(np.arange(0,1,0.001), un_known_acc)\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "plt.legend([\"Known\", \"Unknown\"])\n",
    "\n",
    "known_acc[915], un_known_acc[915]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1bad3-daef-4bdb-83a0-850b85c61f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_prob = np.array(known_acc) * np.array(un_known_acc)\n",
    "\n",
    "plt.plot(np.arange(0,1,0.001), mul_prob)\n",
    "MAX, IDX = np.max(mul_prob), np.argmax(mul_prob)\n",
    "IDX / 1000, known_acc[IDX], un_known_acc[IDX], mul_prob[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239611ae-a081-4bc7-a60b-4caa7bc11088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b992ac7d-cffa-4e6f-8cd7-dcaa21fd44a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14063f5-a9c8-4a77-8d6c-b496ab615524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee1f4b-eccb-4d9a-8a23-b81bd7fc17a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
